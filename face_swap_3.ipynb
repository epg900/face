{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adde136918dc424fb1401cf066bd5753": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_76bb698a9a954732b6b4a1e5c22c8b21",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mProcessing...\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[35m 89%\u001b[0m \u001b[36m0:00:02\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Processing...</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 89%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:02</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "76bb698a9a954732b6b4a1e5c22c8b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Install and Setup\n",
        "!pip install onnx  opencv-python insightface gdown onnxruntime rich\n",
        "#!pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os, subprocess, re, glob, cv2\n",
        "import os.path as osp\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "from insightface.data import get_image as ins_get_image\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "from rich.progress import track\n",
        "\n",
        "def upload_files():\n",
        "    uploaded = files.upload()\n",
        "    return list(uploaded.keys())\n",
        "\n",
        "#/root/.insightface/models/buffalo_l.zip\n",
        "app = FaceAnalysis(name='buffalo_l',providers=['CUDAExecutionProvider']) # , root=str('models/insightface')\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "# Import the library\n",
        "import gdown\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = '1krOLgjW2tAPaqV-Bw4YALz0xT5zlb5HF'\n",
        "# Construct the download URL\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "# Download the file\n",
        "gdown.download(url, 'inswapper_128.onnx', quiet=False)\n",
        "\n",
        "swapper = insightface.model_zoo.get_model('inswapper_128.onnx',download=False,download_zip=False)\n",
        "\n",
        "os.system(\"mkdir output\")\n",
        "os.system(\"mkdir frame\")\n",
        "\n",
        "def ffmpegp(command,desc=''):\n",
        "  process = subprocess.Popen(command.split(), stderr=subprocess.PIPE, universal_newlines=True)\n",
        "  for line in track(iter(process.stderr.readline,''),description=desc):\n",
        "    if \"time=\" in line:\n",
        "      time = re.findall(r\"time=\\s*(\\d{2}:\\d{2}:\\d{2}\\.\\d{2})\", line)\n",
        "\n",
        "def facecompare(face1,face2):\n",
        "  feat1 = face1.normed_embedding\n",
        "  feat2 = face2.normed_embedding\n",
        "  similarity = np.dot(feat1, feat2)\n",
        "  threshold = 0.5\n",
        "  if similarity > threshold:\n",
        "      return True\n",
        "  else:\n",
        "      return False\n",
        "\n",
        "def faceswapdir(face_image,path=\".\",face_id=0,fcfrmid=0):\n",
        "  img1 = cv2.imread(face_image)\n",
        "  lst = os.listdir(path)\n",
        "  lst.sort()\n",
        "  img_lst = [cv2.imread(f\"{path}/{img}\") for img in lst]\n",
        "  base_face = app.get(img1)[0]\n",
        "  face_lst =[app.get(face)[face_id] if app.get(face) else None  for face in img_lst]\n",
        "  out_img = [swapper.get(swap.copy(), face_lst[i], base_face, paste_back=True)  if face_lst[i] is not None  and  facecompare(face_lst[i],face_lst[fcfrmid]) else img_lst[i] for i,swap in enumerate(track(img_lst, description=\"Swap frames \"))]\n",
        "  swapped_img1_rgb = [cv2.cvtColor(swapped, cv2.COLOR_BGR2RGB) for swapped in out_img]\n",
        "\n",
        "  for i,swapped2 in enumerate(swapped_img1_rgb):\n",
        "    Image.fromarray(np.uint8(swapped2)).save(f\"output/{i+1:06}.jpg\")\n",
        "\n",
        "def faceswapdirold(face_image,path=\".\",face_id=0):\n",
        "  img1 = cv2.imread(face_image)\n",
        "  lst = os.listdir(path)\n",
        "  lst.sort()\n",
        "  img_lst = [cv2.imread(f\"{path}/{img}\") for img in lst]\n",
        "  base_face = app.get(img1)[0]\n",
        "  face_lst =[app.get(face)[0] if app.get(face) else None  for face in img_lst]\n",
        "  out_img = [swapper.get(swap.copy(), face_lst[i], base_face, paste_back=True)  if face_lst[i] is not None  else img_lst[i] for i,swap in enumerate(track(img_lst, description=\"Swap frames \"))]\n",
        "  swapped_img1_rgb = [cv2.cvtColor(swapped, cv2.COLOR_BGR2RGB) for swapped in out_img]\n",
        "\n",
        "  for i,swapped2 in enumerate(swapped_img1_rgb):\n",
        "    Image.fromarray(np.uint8(swapped2)).save(f\"output/{i+1:06}.jpg\")\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "pROzTvAo9tau",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run FaceSwap Image\n",
        "!rm -r /content/allpic\n",
        "face_image = upload_files()\n",
        "!mkdir /content/allpic\n",
        "%cd /content/allpic\n",
        "image_files = upload_files()\n",
        "%cd /content\n",
        "\n",
        "faceswapdir(face_image[0],\"/content/allpic\")"
      ],
      "metadata": {
        "id": "11v4HI5W-Olj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Only face upload\n",
        "face_image = upload_files()\n",
        "!cp \"{face_image[0]}\" 7.jpg\n",
        "print('insightface', insightface.__version__)\n",
        "print('numpy', np.__version__)\n",
        "\n",
        "# Check that InsightFace version is at least 0.7\n",
        "assert float('.'.join(insightface.__version__.split('.')[:2])) >= float('0.7')\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "EJCalOKR9MmQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Only Video upload\n",
        "video_file = upload_files()\n",
        "!mv \"{video_file[0]}\" iv.mp4\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Ju2Tx3UKVlu2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run FaceSwap Video\n",
        "fcid = 75 # @param {\"type\":\"integer\"}\n",
        "ffmpegp('ffmpeg -hide_banner -loglevel error  -i iv.mp4 -q:a 0 -map a ia.mp3','Extract Audio ')\n",
        "print('Completed.')\n",
        "ffmpegp('ffmpeg -hide_banner -loglevel error  -hwaccel auto -i iv.mp4 -q:v 18 -pix_fmt rgb24 -vf fps=25  /content/frame/%06d.jpg','Extract frames ')\n",
        "print('Completed.')\n",
        "faceswapdir(face_image[0],\"/content/frame\",fcfrmid=fcid)\n",
        "ffmpegp('ffmpeg -hide_banner -loglevel error  -hwaccel auto -r 25 -i /content/output/%06d.jpg -vcodec libx264 -crf 18  -pix_fmt yuv420p   ov.mp4','Fraems to Video ')\n",
        "print('Completed.')\n",
        "ffmpegp('ffmpeg -hide_banner -loglevel error  -i ov.mp4 -i ia.mp3 -c:v copy -c:a libmp3lame  video.mp4','Merge Video and Audio ')\n",
        "print('Completed.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8k3ZI-OYQbiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract A-B\n",
        "ffmpeg('ffmpeg -ss 00:01:00 -to 00:02:00 -i input.mp4 -c copy output.mp4','Cut A-B ')\n",
        "#!ffmpeg -hide_banner -loglevel error  -i iv.mp4 -q:a 0 -map a ia.mp3\n",
        "#!ffmpeg -hide_banner -loglevel error  -hwaccel auto -i iv.mp4 -q:v 18 -pix_fmt rgb24 -vf fps=25  /content/frame/%06d.jpg\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "EQgxtGtnnGwZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove all files  from frame/output folder\n",
        "!rm -r /content/frame\n",
        "!rm -r /content/output\n",
        "!mkdir /content/output\n",
        "!mkdir /content/frame"
      ],
      "metadata": {
        "cellView": "form",
        "id": "q_9ZjEEP2VIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "from rich.progress import Progress\n",
        "\n",
        "# Assume you have the total_duration in seconds\n",
        "total_duration = 19  # Example: 2 minutes\n",
        "\n",
        "with Progress() as progress:\n",
        "    task_id = progress.add_task(\"[green]Processing...\", total=total_duration)\n",
        "\n",
        "    command = \"ffmpeg -i iv.mp4 ov.mp4\"\n",
        "    process = subprocess.Popen(command.split(), stderr=subprocess.PIPE, universal_newlines=True)\n",
        "    cts=0\n",
        "\n",
        "    for line in iter(process.stderr.readline,''):\n",
        "      if 'time' in line:\n",
        "        h, m, s, ms = re.findall('(\\d{2}):(\\d{2}):(\\d{2}).(\\d{2})', line)[0]\n",
        "        if h and m and s :\n",
        "          cts = int(h)*3600 +  int(m)*60 + int(s)\n",
        "      progress.update(task_id, completed=cts)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36,
          "referenced_widgets": [
            "adde136918dc424fb1401cf066bd5753",
            "76bb698a9a954732b6b4a1e5c22c8b21"
          ]
        },
        "id": "8VRSvc3eRuxz",
        "outputId": "8d548b21-93a9-42df-a7df-abb1d0b96e43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adde136918dc424fb1401cf066bd5753"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}